<?xml version="1.0" encoding="UTF-8"?>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Sampling and Data: Variation and Critical Evaluation</title></head>
<?xml version="1.0"?>
<body
    xmlns:c="http://cnx.rice.edu/cnxml"
    xmlns:md="http://cnx.rice.edu/mdml/0.4"
    xmlns:qml="http://cnx.rice.edu/qml/1.0"
    xmlns:mod="http://cnx.rice.edu/#moduleIds"
    xmlns:bib="http://bibtexml.sf.net/"
    xmlns:data="http://dev.w3.org/html5/spec/#custom"
  ><div
      class="title"
    >Sampling and Data: Variation and Critical Evaluation</div
  > <section
      id="id-612870340664"
    ><h1
        class="title"
      >Variation in Data</h1
    > <p
        class="para"
        id="id8219993"
      >Variation is present in any set of data. For example, 16-ounce cans of beverage may contain more or less than 16 ounces of liquid. In one study, eight 16 ounce cans were measured and produced the following amount (in ounces) of beverage:</p
    > <p
        class="para"
        id="element-25004"
      ><list
          xmlns="http://cnx.rice.edu/cnxml"
          data-id="set-element-984"
          data-list-type="labeled-item"
          data-display="inline"
        ><li
            xmlns=""
            class="item"
          >15.8</li
        > <li
            xmlns=""
            class="item"
          >16.1</li
        > <li
            xmlns=""
            class="item"
          >15.2</li
        > <li
            xmlns=""
            class="item"
          >14.8</li
        > <li
            xmlns=""
            class="item"
          >15.8</li
        > <li
            xmlns=""
            class="item"
          >15.9</li
        > <li
            xmlns=""
            class="item"
          >16.0</li
        > <li
            xmlns=""
            class="item"
          >15.5</li
        ></list
      ></p
    > <p
        class="para"
        id="id6856137"
      >Measurements of the amount of beverage in a 16-ounce can may vary because different people make the measurements or because the exact amount, 16 ounces of liquid, was not put into the cans. Manufacturers regularly run tests to determine if the amount of beverage in a 16-ounce can falls within the desired range.</p
    > <p
        class="para"
        id="id5172174"
      >Be aware that as you take data, your data may vary somewhat from the data someone else is taking for the same purpose. This is completely natural. However, if two or more of you are taking the same data and get very different results, it is time for you and the others to reevaluate your data-taking methods and your accuracy.</p
    > </section
  > <section
      id="id-215528893517"
    ><h1
        class="title"
      >Variation in Samples</h1
    > <p
        class="para"
        id="id11414550"
      >It was mentioned previously that two or more <term
          xmlns="http://cnx.rice.edu/cnxml"
          data-target-id="sample"
        >samples</term
      > from the same <term
          xmlns="http://cnx.rice.edu/cnxml"
          data-target-id="population"
        >population</term
      >, taken randomly, and having close to the same characteristics of the population are different from each other. Suppose Doreen and Jung both decide to study the average amount of time students at their college sleep each night. Doreen and Jung each take samples of 500 students. Doreen uses systematic sampling and Jung uses cluster sampling. Doreen's sample will be different from Jung's sample. Even if Doreen and Jung used the same sampling method, in all likelihood their samples would be different. Neither would be wrong, however. </p
    ><p
        class="para"
        id="id11414555"
      >Think about what contributes to making Doreen's and Jung's samples different. </p
    > <p
        class="para"
        id="id10715475"
      >If Doreen and Jung took larger samples (i.e. the number of data values is increased), their sample results (the average amount of time a student sleeps) might be closer to the actual population average. But still, their samples would be, in all likelihood, different from each other. This <strong
          class="emphasis"
        >variability in samples</strong
      > cannot be stressed enough. </p
    ><section
        id="id-191351579127"
      ><h2
          class="title"
        >Size of a Sample</h2
      > <p
          class="para"
          id="id10291271"
        >The size of a sample (often called the number of observations) is important. The examples you have seen in this book so far have been small. Samples of only a few hundred observations, or even smaller, are sufficient for many purposes. In polling, samples that are from 1200 to 1500 observations are considered large enough and good enough if the survey is random and is well done. You will learn why when you study confidence intervals. <br
        /><br
        /> Be aware that many large samples are biased. For example, call-in surveys are invariable biased because people choose to respond or not.</p
      ></section
    > <section
        id="id-148866396083"
      ><h2
          class="title"
        >Optional Collaborative Classroom Exercise</h2
      > <div
          class="exercise"
          id="element-541"
        ><div
            class="problem"
            id="id1480152"
          > <p
              class="para"
              id="element-363"
            >Divide into groups of two, three, or four. Your instructor will give each group one 6-sided die. <strong
                class="emphasis"
              >Try this experiment twice.</strong
            > Roll one fair die (6-sided) 20 times. Record the number of ones, twos, threes, fours, fives, and sixes you get below ("frequency" is the number of times a particular face of the die occurs): </p
          ><table
              id="element-497"
              summary="This table provides a blank template for recording the results of an experimental trial involving the roll of a die. The first column contains the values 1 through 6, representing the possible outcomes of a single throw of a die. The second column is to be used by the student to tally the number of times the die lands on that value during the experiment."
            ><caption
              ><span
                  class="title"
                >First Experiment (20 rolls)</span
              ></caption
            ><thead
              ><tr
                ><td
                  >Face on Die</td
                ><td
                  >Frequency</td
                ></tr
              ></thead
            ><tbody
              > <tr
                > <td
                  >1</td
                > <td
                /> </tr
              > <tr
                > <td
                  >2</td
                > <td
                /> </tr
              > <tr
                > <td
                  >3</td
                > <td
                /> </tr
              > <tr
                > <td
                  >4</td
                > <td
                /> </tr
              > <tr
                > <td
                  >5</td
                > <td
                /> </tr
              > <tr
                > <td
                  >6</td
                > <td
                /> </tr
              > </tbody
            ></table
          ><table
              id="element-478"
              summary="A duplicate of the previous table, this table provides a blank template for recording the results of an experimental trial involving the roll of a die. The first column contains the values 1 through 6, representing the possible outcomes of a single throw of a die. The second column is to be used by the student to tally the number of times the die lands on that value during the experiment."
            ><caption
              ><span
                  class="title"
                >Second Experiment (20 rolls)</span
              ></caption
            ><thead
              ><tr
                ><td
                  >Face on Die</td
                ><td
                  >Frequency</td
                ></tr
              ></thead
            ><tbody
              > <tr
                > <td
                  >1</td
                > <td
                /> </tr
              > <tr
                > <td
                  >2</td
                > <td
                /> </tr
              > <tr
                > <td
                  >3</td
                > <td
                /> </tr
              > <tr
                > <td
                  >4</td
                > <td
                /> </tr
              > <tr
                > <td
                  >5</td
                > <td
                /> </tr
              > <tr
                > <td
                  >6</td
                > <td
                /> </tr
              > </tbody
            ></table
          ><p
              class="para"
              id="element-663"
            >Did the two experiments have the same results? Probably not. If you did the experiment a third time, do you expect the results to be identical to the first or second experiment? (Answer yes or no.) Why or why not? </p
          ><p
              class="para"
              id="element-440"
            >Which experiment had the correct results? They both did. The job of the statistician is to see through the variability and draw appropriate conclusions.</p
          > </div
        ></div
      > </section
    > </section
  ><section
      id="element-583"
    ><h1
        class="title"
      >Critical Evaluation</h1
    > <p
        class="para"
        id="element-607"
      >We need to critically evaluate the statistical studies we read about and analyze before accepting the results of the study. Common problems to be aware of include </p
    ><ul
        class="list"
        data-id="element-17"
        data-list-type="bulleted"
      ><li
          class="item"
        >Problems with Samples: A sample should be representative of the population. A sample that is not representative of the population is biased. Biased samples that are not representative of the population give results that are inaccurate and not valid.</li
      > <li
          class="item"
        >Self-Selected Samples: Responses only by people who choose to respond, such as call-in surveys are often unreliable.</li
      > <li
          class="item"
        >Sample Size Issues: Samples that are too small may be unreliable. Larger samples are better if possible. In some situations, small samples are unavoidable and can still be used to draw conclusions, even though larger samples are better. Examples: Crash testing cars, medical testing for rare conditions.</li
      > <li
          class="item"
        >Undue influence: Collecting data or asking questions in a way that influences the response.</li
      > <li
          class="item"
        >Non-response or refusal of subject to participate: The collected responses may no longer be representative of the population. Often, people with strong positive or negative opinions may answer surveys, which can affect the results.</li
      > <li
          class="item"
        >Causality: A relationship between two variables does not mean that one causes the other to occur. They may both be related (correlated) because of their relationship through a different variable.</li
      > <li
          class="item"
        >Self-Funded or Self-Interest Studies: A study performed by a person or organization in order to support their claim. Is the study impartial? Read the study carefully to evaluate the work. Do not automatically assume that the study is good but do not automatically assume the study is bad either. Evaluate it on its merits and the work done.</li
      > <li
          class="item"
        >Misleading Use of Data: Improperly displayed graphs, incomplete data, lack of context.</li
      > <li
          class="item"
        >Confounding: When the effects of multiple factors on a response cannot be separated. Confounding makes it difficult or impossible to draw valid conclusions about the effect of each factor.</li
      > </ul
    ></section
  > </body
>
</html>
